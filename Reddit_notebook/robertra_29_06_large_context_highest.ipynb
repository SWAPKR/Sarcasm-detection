{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"robertra_29_06_large_context_highest.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"473192caef614aeeaa92ebc8a210f8be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8f5ca9c1ef140e095d300779502cd7e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_216a99d7de264f7396ff06a3c6e1250f","IPY_MODEL_d4221b9caaf6425ab355ffc1feaa2f05"]}},"b8f5ca9c1ef140e095d300779502cd7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"216a99d7de264f7396ff06a3c6e1250f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2de40b02a1794a72a1dd712f23939722","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f16031003bd34173a27aae88ab42a9a9"}},"d4221b9caaf6425ab355ffc1feaa2f05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_618c29f53c914864aa53e466a95a7426","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 482/482 [00:00&lt;00:00, 11.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ecd4b6ce9f043e3b4280df5f73c5a05"}},"2de40b02a1794a72a1dd712f23939722":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f16031003bd34173a27aae88ab42a9a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"618c29f53c914864aa53e466a95a7426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0ecd4b6ce9f043e3b4280df5f73c5a05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b48856bbc7ea41f29ddb284923862ccd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f5702e48c4f447d883b816c3ca25dccf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_82e2aaa8d9eb45e1851c8acbd9f7cb0b","IPY_MODEL_a6174bd292224bb5b3163f19aa4407e0"]}},"f5702e48c4f447d883b816c3ca25dccf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"82e2aaa8d9eb45e1851c8acbd9f7cb0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5e4176c80daf4d3999d3e3a42955b883","_dom_classes":[],"description":"Downloading:  22%","_model_name":"FloatProgressModel","bar_style":"","max":1425941629,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":310174720,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2aa95653321c4498be35bc992fe3accb"}},"a6174bd292224bb5b3163f19aa4407e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fe2e892dfead4067ac8ea1c86be027f4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 310M/1.43G [00:06&lt;00:22, 49.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79be223df4fe40bc8ceb8d3ce0397d00"}},"5e4176c80daf4d3999d3e3a42955b883":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2aa95653321c4498be35bc992fe3accb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe2e892dfead4067ac8ea1c86be027f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79be223df4fe40bc8ceb8d3ce0397d00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"OFOTiqrtNvyy"},"source":["# Install Transformers Library"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7sYuExU3YiR4","executionInfo":{"status":"ok","timestamp":1626858041928,"user_tz":-330,"elapsed":30925,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"46dad6c1-5eee-4a17-b111-6e62161f52eb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hkhc10wNrGt","executionInfo":{"status":"ok","timestamp":1626858131356,"user_tz":-330,"elapsed":8269,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"ba205d5e-26cc-47d4-fab5-4a94f4f9f403"},"source":["!pip install transformers"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 42.3 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 51.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x4giRzM7NtHJ","executionInfo":{"status":"ok","timestamp":1626858131357,"user_tz":-330,"elapsed":7,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import transformers\n","# from transformers import AutoModel, BertTokenizerFast\n","from transformers import RobertaTokenizer, RobertaModel\n","# specify GPU\n","# device = torch.device(\"cuda\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"cwJrQFQgN_BE","executionInfo":{"status":"ok","timestamp":1626858133010,"user_tz":-330,"elapsed":1658,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"d4543e4b-9e67-450c-9508-4db1a383a6b1"},"source":["df = pd.read_json('/content/drive/MyDrive/sarcasm detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_training.jsonl',lines=True)\n","df1 = pd.read_json('/content/drive/MyDrive/sarcasm detection/Datasets/reddit/sarcasm_detection_shared_task_reddit_testing.jsonl',lines=True)\n","\n","df['labels'] = df['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1['labels'] = df1['label'].apply(lambda x: ['SARCASM', 'NOT_SARCASM'].index(x))\n","df1.tail()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>context</th>\n","      <th>response</th>\n","      <th>id</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1795</th>\n","      <td>SARCASM</td>\n","      <td>[Spoiler Cristiane Justino vs. Amanda Nunes, H...</td>\n","      <td>she will probably beat him too. she can fight ...</td>\n","      <td>reddit_1796</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1796</th>\n","      <td>NOT_SARCASM</td>\n","      <td>[Treyarch makes the most unbalanced game ever....</td>\n","      <td>No, but then the game really glitch(ed) out fo...</td>\n","      <td>reddit_1797</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1797</th>\n","      <td>SARCASM</td>\n","      <td>[First Official Image from \"Zombieland: Double...</td>\n","      <td>&gt; Zombieland ~~2:~~ Double Tap They changed it...</td>\n","      <td>reddit_1798</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1798</th>\n","      <td>SARCASM</td>\n","      <td>[Its time to ban /r/The_Donald: Calling out sp...</td>\n","      <td>We're not *supporting racists* and prospective...</td>\n","      <td>reddit_1799</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1799</th>\n","      <td>SARCASM</td>\n","      <td>[59 Alabama ministers sign a letter saying Roy...</td>\n","      <td>Is she old enough to have Facebook</td>\n","      <td>reddit_1800</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            label  ... labels\n","1795      SARCASM  ...      0\n","1796  NOT_SARCASM  ...      1\n","1797      SARCASM  ...      0\n","1798      SARCASM  ...      0\n","1799      SARCASM  ...      0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pwj1A_77nh7i","executionInfo":{"status":"ok","timestamp":1626863496370,"user_tz":-330,"elapsed":372,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"5e37c43d-c54b-4b3c-d227-afcc190bbaf7"},"source":["df.loc[10,'context']"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@USER if you had a fever would the pancakes be bigger ? maybe even giant size ? ( just asking for a friend with a fever )',\n"," '@USER she will be so happy to hear it , tho will probably wait until the ability to taste food returns .']"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"16SPRbU6-cPf"},"source":["from sklearn.utils import shuffle\n","df=shuffle(df,random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DIY6yOMr8sdX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437843155,"user_tz":-330,"elapsed":9902,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"414407ec-dbec-4b48-c022-a54ca50b9d27"},"source":["import pandas as pd\n","import re\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.corpus import stopwords\n","import re\n","import string\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tqdm.auto import tqdm\n","!pip install demoji\n","!pip install contractions\n","import demoji\n","import contractions\n","\n","demoji.download_codes()\n","nltk.download('stopwords') \n","# nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting demoji\n","  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from demoji) (2.23.0)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2.10)\n","Installing collected packages: colorama, demoji\n","Successfully installed colorama-0.4.4 demoji-0.4.0\n","Collecting contractions\n","  Downloading https://files.pythonhosted.org/packages/93/f4/0ec4a458e4368cc3be2c799411ecf0bc961930e566dadb9624563821b3a6/contractions-0.0.52-py2.py3-none-any.whl\n","Collecting textsearch>=0.0.21\n","  Downloading https://files.pythonhosted.org/packages/d3/fe/021d7d76961b5ceb9f8d022c4138461d83beff36c3938dc424586085e559/textsearch-0.0.21-py2.py3-none-any.whl\n","Collecting anyascii\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/14/666cd44bf53f36a961544af592cb5c5c800013f9c51a4745af8d7c17362a/anyascii-0.2.0-py3-none-any.whl (283kB)\n","\u001b[K     |████████████████████████████████| 286kB 10.4MB/s \n","\u001b[?25hCollecting pyahocorasick\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/c2/eae730037ae1cbbfaa229d27030d1d5e34a1e41114b21447d1202ae9c220/pyahocorasick-1.4.2.tar.gz (321kB)\n","\u001b[K     |████████████████████████████████| 327kB 28.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85392 sha256=a54438c62a3bfd12bdffb3123310aef1b3947930704dbf4a12250c84a9732aeb\n","  Stored in directory: /root/.cache/pip/wheels/3a/03/34/77e3ece0bba8b86bfac88a79f923b36d805cad63caeba38842\n","Successfully built pyahocorasick\n","Installing collected packages: anyascii, pyahocorasick, textsearch, contractions\n","Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n","Downloading emoji data ...\n","... OK (Got response in 0.14 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Z5qBvDp14S4z"},"source":["def preprocess_text(text):\n","    # Tokenise words while ignoring punctuation(https://www.nltk.org/_modules/nltk/tokenize/regexp.html)\n","    text = re.sub(r\"@\",'', text)\n","    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)\n","    text = re.sub(r\"USER\",'@USER', text)\n","    # text = re.sub(r\"USER\",'', text)\n","    text = re.sub(r'<URL>','',text)\n","\n","    text = demoji.replace_with_desc(text)\n","    text = re.sub(r':','',text)\n","    text = contractions.fix(text)\n","    # text = re.sub(r'\\.+','',text)\n","    # tokeniser = RegexpTokenizer(r'\\s+', gaps=True)\n","    # tokeniser = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n","    # tokeniser = RegexpTokenizer(r'\\w+')\n","    # tokens = tokeniser.tokenize(text)\n","\n","    # Lowercase and lemmatise \n","    # lemmatiser = WordNetLemmatizer()\n","    # lemmas = [lemmatiser.lemmatize(token.lower(), pos='v') for token in tokens]\n","    \n","    # Remove stopwords\n","    # keywords= [lemma for lemma in lemmas if lemma not in stopwords.words('english')]\n","    \n","    # stemming\n","    # ps=PorterStemmer()\n","    # keywords=[ps.stem(x) for x in keywords]\n","    return text\n","\n","def preprocess_text2(tweet):\n","    \"\"\"Process tweet function.\n","    Input:\n","        tweet: a string containing a tweet\n","    Output:\n","        tweets_clean: a list of words containing the processed tweet\n","\n","    \"\"\"\n","    stemmer = PorterStemmer()\n","    stopwords_english = stopwords.words('english')\n","    # remove stock market tickers like $GE\n","    tweet = re.sub(r'\\$\\w*', '', tweet)\n","    # remove old style retweet text \"RT\"\n","    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","    # remove hyperlinks\n","    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n","    # remove hashtags\n","    # only removing the hash # sign from the word\n","    tweet = re.sub(r'#', '', tweet)\n","    # tokenize tweets\n","    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n","                               reduce_len=True)\n","    tweet_tokens = tokenizer.tokenize(tweet)\n","\n","    tweets_clean = []\n","    for word in tweet_tokens:\n","        if (word not in stopwords_english and  # remove stopwords\n","                word not in string.punctuation):  # remove punctuation (optional)\n","            # tweets_clean.append(word)\n","            stem_word = stemmer.stem(word)  # stemming word\n","            tweets_clean.append(stem_word)\n","\n","    return tweets_clean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj-zpWUjt0IB"},"source":["def fun(A,l):\n","  if len(A)<=l:\n","    return A\n","  else:\n","    # return A[-l::1]\n","    return A[-1:-l-1:-1]\n","def fun1(A):\n","  return ''.join(A)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3DFJt513x7X"},"source":["l=0\n","\n","# df['tweets']= df['response'] +'reply-'+ df['context'].apply(fun,args=[l]).apply(fun1)\n","# df1['tweets']=df1['response'] +'reply-'+ df1['context'].apply(fun,args=[l]).apply(fun1)\n","\n","\n","\n","\n","\n","\n","df['tweets']= df['context'].apply(fun,args=[l]).apply(fun1) +'reply-'+ df['response']\n","df1['tweets']= df1['context'].apply(fun,args=[l]).apply(fun1) +'reply-'+ df1['response']\n","\n","\n","# df['tweets']= df['context'].apply(fun,args=[l]).apply(fun1) + df['response']\n","# df1['tweets']= df1['context'].apply(fun,args=[l]).apply(fun1) + df1['response']\n","\n","df['tweets']= df['tweets'].apply(preprocess_text) \n","df1['tweets']=df1['tweets'].apply(preprocess_text)\n","# df['tweets']=df['tweets']+'reply-'+ df['response'].apply(preprocess_text)\n","# df1['tweets']=df1['tweets']+'reply-'+ df1['response'].apply(preprocess_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"676DPU1BOPdp","executionInfo":{"status":"ok","timestamp":1626437878032,"user_tz":-330,"elapsed":5,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"b43ffed0-bf81-4c14-dab0-7a73970218c9"},"source":["# check class distribution\n","df['labels'].value_counts(normalize = True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    0.5\n","0    0.5\n","Name: labels, dtype: float64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"mjLmL_LFtVjo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626437878503,"user_tz":-330,"elapsed":6,"user":{"displayName":"swapnil kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9vEVcpw4Md19MxYrt28Nw5e4xMxyCx3xoMPqseg=s64","userId":"09398363863484464628"}},"outputId":"da923317-a128-49fa-c83c-74ec2280b032"},"source":["df['tweets']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["274     reply-Because Kentucky is such a crucial battl...\n","3430    reply-Well you have to spin the xray emitter a...\n","4324    reply-I think the people who complain the most...\n","1027    reply-does not help when you have legendary me...\n","1589          reply-it is 2x2 tho, nobody cares about 2x2\n","                              ...                        \n","3444    reply-Or we can lead and come up with innovati...\n","466     reply-Nah, it is all a conspiracy by the Clint...\n","3092    reply-Do you have a source for how much the NS...\n","3772    reply-I kind of wish he would go back to a Mit...\n","860     reply-Of course you do not have a job, you stu...\n","Name: tweets, Length: 4400, dtype: object"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"MKfWnApvOoE7"},"source":["# Split train dataset into train, validation and test sets"]},{"cell_type":"code","metadata":{"id":"mfhSPF5jOWb7"},"source":["\n","X_s = df['tweets'].values\n","y_s = df['labels'].values\n","\n","Xt_s = df1['tweets'].values\n","yt_s = df1['labels'].values\n","\n","train_text, temp_text, train_labels, temp_labels = X_s,Xt_s,y_s,yt_s\n","\n","# we will use temp_text and temp_labels to create validation and test set\n","val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n","                                                                random_state=2018, \n","                                                                test_size=0.5, \n","                                                                stratify=temp_labels)\n","val_text, test_text, val_labels, test_labels=temp_text, temp_text, temp_labels, temp_labels\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.2, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1jEFb39cCjk"},"source":["# pip install -U sentence-transformers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7hsdLoCO7uB"},"source":["# Import BERT Model and BERT Tokenizer\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["473192caef614aeeaa92ebc8a210f8be","b8f5ca9c1ef140e095d300779502cd7e","216a99d7de264f7396ff06a3c6e1250f","d4221b9caaf6425ab355ffc1feaa2f05","2de40b02a1794a72a1dd712f23939722","f16031003bd34173a27aae88ab42a9a9","618c29f53c914864aa53e466a95a7426","0ecd4b6ce9f043e3b4280df5f73c5a05","b48856bbc7ea41f29ddb284923862ccd","f5702e48c4f447d883b816c3ca25dccf","82e2aaa8d9eb45e1851c8acbd9f7cb0b","a6174bd292224bb5b3163f19aa4407e0","5e4176c80daf4d3999d3e3a42955b883","2aa95653321c4498be35bc992fe3accb","fe2e892dfead4067ac8ea1c86be027f4","79be223df4fe40bc8ceb8d3ce0397d00"]},"id":"S1kY3gZjO2RE","outputId":"3ce63756-5859-4fcc-e67c-1737fadb4f9a"},"source":["# import BERT-base pretrained model\n","# bert = AutoModel.from_pretrained('bert-base-uncased')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","# import BERT-base pretrained model\n","\n","\n","# from transformers import RobertaTokenizer, TFRobertaModel\n","# bert = RobertaModel.from_pretrained('roberta-base')\n","\n","# # Load the BERT tokenizer\n","# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","from transformers import RobertaTokenizer, TFRobertaModel\n","bert = RobertaModel.from_pretrained('roberta-large')\n","\n","# Load the BERT tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-large')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"473192caef614aeeaa92ebc8a210f8be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b48856bbc7ea41f29ddb284923862ccd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425941629.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"_zOKeOMeO-DT"},"source":["# sample data\n","text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n","# encode text\n","sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAH73n39PHLw"},"source":["# output\n","print(sent_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8wIYaWI_Prg8"},"source":["# Tokenization"]},{"cell_type":"code","metadata":{"id":"yKwbpeN_PMiu"},"source":["# # get length of all the messages in the train set\n","# seq_len = [len(i.split()) for i in train_text]\n","# for i in train_text:\n","#   print(i)\n","# pd.Series(seq_len).hist(bins = 30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OXcswEIRPvGe"},"source":["# max_seq_len = 190\n","max_seq_len = 128"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGcvb0cV5irf"},"source":["total=0\n","for i in range(5000):\n","  total+=len(df['tweets'][i].split(' '))\n","total/5000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk5S7DWaP2t6"},"source":["# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length = max_seq_len,\n","    pad_to_max_length=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wsm8bkRZQTw9"},"source":["# Convert Integer Sequences to Tensors"]},{"cell_type":"code","metadata":{"id":"QR-lXwmzQPd6"},"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ov1cOBlcRLuk"},"source":["# Create DataLoaders"]},{"cell_type":"code","metadata":{"id":"qUy9JKFYQYLp"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","#define a batch size\n","batch_size = 16\n","\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)#,shuffle=True)\n","\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K2HZc5ZYRV28"},"source":["# Freeze BERT Parameters"]},{"cell_type":"code","metadata":{"id":"wHZ0MC00RQA_"},"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = True\n","# print(bert)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7ahGBUWRi3X"},"source":["# Define Model Architecture"]},{"cell_type":"code","metadata":{"id":"b3iEtGyYRd0A"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      \n","      # dropout layer\n","      self.dropout = nn.Dropout(0.1)\n","      \n","      # relu activation function\n","      self.relu =  nn.ReLU()\n","\n","      # dense layer 1\n","      # self.fc1 = nn.Linear(768,256)\n","      self.fc1 = nn.Linear(1024,256)\n","      # dense layer 2 (Output layer)\n","      self.fc2 = nn.Linear(256,2)\n","\n","      #softmax activation function\n","      self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      _, cls_hs = self.bert(sent_id,mask, return_dict=False)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn11111 \",cls_hs.shape)\n","      x = self.fc1(cls_hs)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.relu(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      x = self.dropout(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # output layer\n","      x = self.fc2(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      # apply softmax activation\n","      x = self.softmax(x)\n","      # print(\"dfghjjhfchgbhlvmb jfbvfddvfgbhnjhgvcvtynubtrvcebnuexcvbnbtvrcedcvbnjbnjn22222 \",x.shape)\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cBAJJVuJRliv"},"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"taXS0IilRn9J"},"source":["# optimizer from hugging face transformers\n","from transformers import AdamW\n","\n","# define the optimizer\n","optimizer = AdamW(model.parameters(), lr = 2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9CDpoMQR_rK"},"source":["# Find Class Weights"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izY5xH5eR7Ur","outputId":"e56a3070-44fe-460f-bbc9-a8ec7eb868f0"},"source":["from sklearn.utils.class_weight import compute_class_weight\n","\n","#compute the class weights\n","class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","\n","print(class_wts)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1. 1.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r1WvfY2vSGKi"},"source":["# convert class weights to tensor\n","weights= torch.tensor(class_wts,dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","# number of training epochs\n","epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"My4CA0qaShLq"},"source":["# Fine-Tune BERT"]},{"cell_type":"code","metadata":{"id":"rskLk8R_SahS"},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yGXovFDlSxB5"},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","      # elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHQlio6yM_QH","outputId":"3054e8e5-2ad5-4d23-b1ea-9ddb12940f8c"},"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Jul 12 10:21:19 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   50C    P0    63W / 149W |   1816MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9KZEgxRRTLXG"},"source":["# Start Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k1USGTntS3TS","outputId":"f61da1eb-487a-4c1d-8966-46654e09dc11"},"source":["# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","epochs=1\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss,_ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    # if valid_loss < best_valid_loss:\n","    best_valid_loss = valid_loss\n","    torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","  \n","    # get predictions for test data\n","    !nvidia-smi\n","    # with torch.no_grad():\n","    0.\n","    #   preds = model(test_seq.to(device), test_mask.to(device))\n","    #   preds = preds.detach().cpu().numpy()\n","    # preds = np.argmax(preds, axis = 1)\n","    # print(classification_report(test_y, preds))\n","    # print(accuracy_score(test_y, preds))\n","\n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"," Epoch 1 / 1\n","  Batch    50  of    313.\n","  Batch   100  of    313.\n","  Batch   150  of    313.\n","  Batch   200  of    313.\n","  Batch   250  of    313.\n","  Batch   300  of    313.\n","\n","Evaluating...\n","  Batch    50  of    113.\n","  Batch   100  of    113.\n","Mon Jul 12 11:07:36 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P0    65W / 149W |  10591MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","\n","Training Loss: 0.522\n","Validation Loss: 0.623\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_yrhUc9kTI5a"},"source":["# Load Saved Model"]},{"cell_type":"code","metadata":{"id":"OacxUyizS8d1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c159e99d-10d9-4ac5-8bad-2fb83de1c029"},"source":["#load weights of best model\n","path = 'saved_weights.pt'\n","model.load_state_dict(torch.load(path))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"x4SVftkkTZXA"},"source":["# Get Predictions for Test Data"]},{"cell_type":"code","metadata":{"id":"NZl0SZmFTRQA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"76f128f9-4e08-4a26-8622-92e001b4c4fa"},"source":["pred=[]\n","with torch.no_grad():\n","  for i in range(0,90):\n","    preds = model(test_seq[i*20:i*20+20].to(device), test_mask[i*20:i*20+20].to(device))\n","    preds = preds.detach().cpu().numpy()\n","    pred.append(preds)\n","print(np.array(pred).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(90, 20, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nxx02ZloNigE"},"source":["pred1=np.array(pred)\n","# pred1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"npjCx1x0NlLL","outputId":"4dd76f2f-ad43-40a8-d5c1-dc70c7fd0039"},"source":["pred2=pred1.reshape((1800,2))\n","pred2.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1800, 2)"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"nQ_1m2WhgL7k"},"source":["p=pd.DataFrame(pred2)\n","p.to_csv('context_2.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8su6xM8gSNJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"23fe8b0d-aaff-4679-8303-3fcb445e365a"},"source":["pred3 = np.argmax(pred2, axis = 1)\n","pred3 "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 1, 1])"]},"metadata":{"tags":[]},"execution_count":60}]},{"cell_type":"code","metadata":{"id":"ZMw2NRnngSQs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45d29cdd-0c76-493d-821f-a9b0080b4880"},"source":["print(classification_report(test_y, pred3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.67      0.86      0.75       900\n","           1       0.80      0.57      0.67       900\n","\n","    accuracy                           0.71      1800\n","   macro avg       0.74      0.72      0.71      1800\n","weighted avg       0.74      0.71      0.71      1800\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5K4dl1AQgShx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"addf3f8c-0466-4e70-f139-04d4446eeaf7"},"source":["# confusion matrix\n","# print(pred)\n","pd.crosstab(test_y, pred3)\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, pred3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.715\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W14537b4ubb6"},"source":["import scipy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G0psIEgeubdz","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"40c7a9b0-c3c6-4c79-9228-d73d1ce4b3ed"},"source":["brcc=pd.read_csv('76.6_roberta_large_100_32_2e-5_4epoch_preprocessing+@reply+user.csv')\n","brcc=np.array(brcc[['0','1']])\n","brcc=scipy.special.softmax(brcc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","brcc"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-6e501d934cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbrcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'76.6_roberta_large_100_32_2e-5_4epoch_preprocessing+@reply+user.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbrcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrcc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbrcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrcc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# bsvm=np.multiply(bsvm,-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbrcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '76.6_roberta_large_100_32_2e-5_4epoch_preprocessing+@reply+user.csv'"]}]},{"cell_type":"code","metadata":{"id":"1eyDGkYuubhK"},"source":["brc=pd.read_csv('77.44_1context+response_batch16+3epoch_180maxlen.csv')\n","brc=np.array(brc[['0','1']])\n","brc=scipy.special.softmax(brc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","brc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ms1ObHZxTYSI"},"source":["br=pd.read_csv('77.7_2context+response_batch16+4epoch_190maxlen.csv')\n","br=np.array(br[['0','1']])\n","br=scipy.special.softmax(br,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","br"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqzLS7rHTp4T"},"source":["bc=pd.read_csv('76.56_2context_+response_temserflow.csv')\n","bc=np.array(bc[['0','1']])\n","bc=scipy.special.softmax(bc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","bc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_HPa0uXH6he"},"source":["bkc=pd.read_csv('75_lstm_base_response.csv')\n","bkc=np.array(bkc[['0','1']])\n","bkc=scipy.special.softmax(bkc,axis=1)\n","# bsvm=np.multiply(bsvm,-1)\n","bkc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpX1uTwjUPY6"},"source":["# bertc=np.array(bc[['0','1']])\n","bertc1=np.multiply(bc,0.6)\n","\n","# bertrcc=np.array(brcc[['0','1']])\n","bertrcc1=np.multiply(brcc,0.8)\n","\n","# bertcr=np.array(brc[['0','1']])\n","bertcr1=np.multiply(brc,0.6)\n","\n","# bertr=np.array(br[['0','1']])\n","bertr1=np.multiply(br,0.45)\n","\n","\n","\n","# # bertc=np.array(bc[['0','1']])\n","# bertc1=np.multiply(bc,0.4)\n","\n","# # bertrcc=np.array(brcc[['0','1']])\n","# bertrcc1=np.multiply(brcc,0.8)\n","\n","# # bertcr=np.array(brc[['0','1']])\n","# bertcr1=np.multiply(brc,0.4)\n","\n","# bertr=np.array(br[['0','1']])\n","# bertr1=np.multiply(br,0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY2P7H1W2Wo4"},"source":["yhats = [bertc1,bertr1,bertcr1,bertrcc1]\n","# yhats = [bertcr1,bertrcc1,bertr1]\n","# yhats = [bertcr1,bertrcc1,bertr1]\n","# import numpy as np\n","# yhats = np.array(yhats)\n","\n","# # sum across ensemble members\n","# summed = np.sum(yhats, axis=0)\n","# # argmax across classes\n","# result = np.argmax(summed, axis=1)\n","\n","# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","# accuracy_score(result,test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33vNifQf_Ojz"},"source":["ans=[]\n","yhat=[bc,br,brcc,brc,bkc]\n","# yhat=[brcc,br,brc]\n","for i in yhat:\n","  ans.append(np.argmax(i, axis=1))\n","summed = np.sum(ans, axis=0)/4\n","res=[]\n","for i in summed:\n","  if i<=0.5:\n","    res.append(0)\n","  else:\n","    res.append(1)\n","\n","print(res)\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","# accuracy_score(res,test_y)\n","\n","\n","print(classification_report(test_y, res))\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, res))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZlyjQR97WAfz"},"source":["#Ensembling"]},{"cell_type":"code","metadata":{"id":"MjQgnPrvWdFB","executionInfo":{"status":"ok","timestamp":1626808637745,"user_tz":-330,"elapsed":399,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["import pandas as pd\n","import numpy as np\n","from scipy import special"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HrxQUTUCVz1D","executionInfo":{"status":"ok","timestamp":1626808638679,"user_tz":-330,"elapsed":547,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["b3c=pd.read_csv('/content/drive/MyDrive/sarcasm detection/Results/reddit/71.388_response+3contest_5epoch_120len_32_batch_1e-5lr ().csv')\n","b3c=np.array(b3c[['0','1']])\n","b3c=special.softmax(b3c,axis=1)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"cgdlzSjTVzzY","executionInfo":{"status":"ok","timestamp":1626808678744,"user_tz":-330,"elapsed":1069,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["br=pd.read_csv('/content/drive/MyDrive/sarcasm detection/Results/reddit/70.8_Rresponsereddit_1e-5_5_epoch_learnigrate  anually changed.csv')\n","\n","br=np.array(br[['0','1']])\n","br=special.softmax(br,axis=1)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"kW3k32aeVzyP","executionInfo":{"status":"ok","timestamp":1626809354248,"user_tz":-330,"elapsed":412,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["test_y=df1['labels'].values"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5MKjzLWVzpZ","executionInfo":{"status":"ok","timestamp":1626808723104,"user_tz":-330,"elapsed":439,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"61c5ba70-9fd7-4268-d021-d58430fc1bd9"},"source":["ans=[]\n","yhat=[br,b3c]\n","# yhat=[brcc,br,brc]\n","for i in yhat:\n","  ans.append(np.argmax(i, axis=1))\n","summed = np.sum(ans, axis=0)/len(yhat)\n","res=[]\n","for i in summed:\n","  if i<=0.5:\n","    res.append(0)\n","  else:\n","    res.append(1)\n","\n","print(res)\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n","# accuracy_score(res,test_y)\n","\n","\n","print(classification_report(test_y, res))\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, res))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.79      0.73       900\n","           1       0.75      0.63      0.69       900\n","\n","    accuracy                           0.71      1800\n","   macro avg       0.72      0.71      0.71      1800\n","weighted avg       0.72      0.71      0.71      1800\n","\n","0.7111111111111111\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lXCwvbZWVzYR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q66zE1v5YuS2"},"source":["#Augumentation Ensembling"]},{"cell_type":"code","metadata":{"id":"oNBXQ29HVzUb","executionInfo":{"status":"ok","timestamp":1626809301281,"user_tz":-330,"elapsed":453,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["\n","b3c=pd.read_csv('/content/drive/MyDrive/sarcasm detection/Results/arg_twitter/76.38_120len_4epoch_32batch_3context.csv')\n","b3c=np.array(b3c[['0','1']])\n","b3c=special.softmax(b3c,axis=1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6qLfVhuVzSm","executionInfo":{"status":"ok","timestamp":1626809326695,"user_tz":-330,"elapsed":647,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["br=pd.read_csv('/content/drive/MyDrive/sarcasm detection/Results/arg_twitter/77.27_argumented_32_120_response_4epoch.csv')\n","br=np.array(br[['0','1']])\n","br=special.softmax(br,axis=1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xYzz4atVzQW","executionInfo":{"status":"ok","timestamp":1626809357836,"user_tz":-330,"elapsed":4,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"d56ada1a-ebcc-44e1-c967-c460c01403fd"},"source":["ans=[]\n","yhat=[br,b3c]\n","# yhat=[brcc,br,brc]\n","for i in yhat:\n","  ans.append(np.argmax(i, axis=1))\n","summed = np.sum(ans, axis=0)/len(yhat)\n","res=[]\n","for i in summed:\n","  if i<=0.5:\n","    res.append(0)\n","  else:\n","    res.append(1)\n","\n","print(res)\n","\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report\n","# accuracy_score(res,test_y)\n","\n","\n","print(classification_report(test_y, res))\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","print(accuracy_score(test_y, res))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n","              precision    recall  f1-score   support\n","\n","           0       0.50      0.62      0.55       900\n","           1       0.50      0.38      0.43       900\n","\n","    accuracy                           0.50      1800\n","   macro avg       0.50      0.50      0.49      1800\n","weighted avg       0.50      0.50      0.49      1800\n","\n","0.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBvJvZrfZIn7","executionInfo":{"status":"ok","timestamp":1626858065037,"user_tz":-330,"elapsed":650,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["dfArg_c=pd.read_csv('/content/drive/MyDrive/sarcasm detection/augumented_data/context1.csv')\n","dfArg_r=pd.read_csv('/content/drive/MyDrive/sarcasm detection/augumented_data/response3.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_-mSOCNS92h","executionInfo":{"status":"ok","timestamp":1626858161213,"user_tz":-330,"elapsed":387,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"a2c873cc-5df6-4068-8e2c-5654212c061e"},"source":[""],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0,\n","        \"@ user online don't get it.. think you don't expect, is only would, moved right along.. instead either pretend to bear care of them an troll them..\"],\n","       [1,\n","        '@ user tries to protest again. talk about jake and his mate think they label with wtf does jones?'],\n","       [2,\n","        '@ show the lives about madness about money life moves, oh! # learnhowthesystemworks'],\n","       ...,\n","       [4997,\n","        '@ user *\\'rec right... \" yes! # protection now impossible # privacy makes not \"'],\n","       [4998,\n","        '@ user diary - delusional voter who takes the word still not chosen at least value instead of researching : finding out that s / he s off being performed to'],\n","       [4999,\n","        \"@ user i hope you know no news from this have said anything about that luxurious restaurant ('sokoto on to the east ) passengers kidnapped by armed men on nine may 1987? among them is one of your former patients.\"]],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"gYM2KNd7TJhO","executionInfo":{"status":"ok","timestamp":1626858320919,"user_tz":-330,"elapsed":385,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}}},"source":["df = pd.read_json('/content/drive/MyDrive/sarcasm detection/Datasets/twitter/sarcasm_detection_shared_task_twitter_training.jsonl',lines=True)\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"e4tap-aVT_Ad","executionInfo":{"status":"ok","timestamp":1626858460744,"user_tz":-330,"elapsed":368,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"41025f09-d343-454f-950e-98ee22a39542"},"source":["df['response'][4]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'@USER @USER Pretty Sure the Anti-Lincoln Crowd Claimed That \" Democracy Was on the Ballot \" in 1860 , too . They Thought Lincoln Was \" Authoritarian \" . #GOP #PartyOfLincoln #Democrats'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MPH0CS3UFhr","executionInfo":{"status":"ok","timestamp":1626858463669,"user_tz":-330,"elapsed":6,"user":{"displayName":"SWAPNIL KUMAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgsLZIPPZoD8cm6pYXnJ-E5s3jPYct0P1FaVpMB1w=s64","userId":"13060826743241505268"}},"outputId":"bde869ab-ab38-4394-d33f-45b6dbba1019"},"source":["dfArg_r.values[4]"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4,\n","       '@ and pretty sure that the a - lincoln word of ( \" what was on the ballot \" here 1860, too. personal support lincoln was \" authoritarian \". # gop # partyoflincoln # action'],\n","      dtype=object)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"aNl4ad2_USG3"},"source":[""],"execution_count":null,"outputs":[]}]}